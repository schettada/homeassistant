# Amazon Face Recognition for Home Assistant

## A complete face recognition ecosystem for Home Assistant

![Amazon Face Recognition](images/spot.png)

**Amazon Face Recognition** is a **full-featured ecosystem for Home Assistant**, composed of:

- ðŸ§  a **custom integration** (backend & AWS communication)
- ðŸ–¥ a **dedicated Custom Control Panel** (configuration & management)
- ðŸ–¼ a **built-in Custom Lovelace Card** (visualization)

All components are designed together as a **single, coherent system**.
There is **no legacy configuration**, no YAML setup and no external tools required.

Everything is managed directly from the Home Assistant UI.

---

## Core concepts

- AWS Rekognition is used as the AI engine
- Home Assistant is the single control point
- The **Custom Panel is the source of truth**
- Local cache is always synchronized with AWS
- The Custom Card is automatically available for dashboards
- Multilingual UI (auto-detected from Home Assistant)

---

## Main Features

### ðŸ‘¤ Face Recognition
- Face recognition using **AWS Rekognition Face Collections**
- Known / unknown face separation
- Annotated snapshots with bounding boxes
- Local face index automatically synchronized at startup
- Face recognition fully managed from the UI

### ðŸ–¼ Face Gallery & Management
- Visual face gallery inside Home Assistant
- Upload training images directly from the panel
- Delete individual identities or clear the entire collection
- No services or YAML required
- Local cache always aligned with AWS

### ðŸŽ¯ ROI (Region of Interest)
- Define multiple ROIs per camera
- Visual ROI editor
- Analyze only specific image areas
- Reduce false positives and AWS costs

### ðŸš— Vehicle & License Plate Recognition
- Vehicle detection (car, truck, motorcycle, bus)
- License plate OCR
- Plate â†’ owner mapping
- Dedicated Plates panel
- Annotated snapshots with vehicle and plate boxes

## Face Gallery

![Amazon Face Recognition](images/gallery_demo.png)



The **Gallery** is the visual core of the Amazon Face Recognition ecosystem.  
It provides a **real-time and historical view** of all processed images, detected faces, vehicles and license plates.

The Gallery is tightly integrated with the backend and always reflects the **current local cache state**, which is automatically synchronized with AWS.

---

## What the Gallery shows

The Gallery displays:

- ðŸ–¼ **Annotated snapshots** generated by the integration
- ðŸ‘¤ **Recognized faces** with assigned names
- â“ **Unrecognized faces**
- ðŸš— **Detected vehicles**
- ðŸ”¢ **Recognized license plates**
- ðŸ•’ Timestamps and camera source
- ðŸŽ¯ ROI-based detections only (if ROI is enabled)

Each image represents a **real analysis result**, not a static preview.

---

## Gallery Sections

The Gallery is divided into logical sections to improve clarity and usability.

### Face Collection Overview
At the top of the Gallery, you can see:
- The number of persons currently stored in the AWS face collection
- The local face index status
- The last synchronization timestamp

This section reflects the **actual state of AWS Rekognition**.

---

### Snapshot List
The main area shows the list of saved snapshots.

For each snapshot you can:
- See detection results at a glance
- Identify which camera generated the image
- Check when the detection occurred

Snapshots are ordered chronologically, with the most recent at the top.

---

## Interacting with Gallery Items

Clicking on a snapshot allows you to:

- ðŸ” View the image in full resolution
- ðŸ‘¤ Inspect detected faces and labels
- ðŸš— Review vehicles and license plates
- ðŸ§­ See bounding boxes and confidence overlays
- ðŸ•’ Analyze detection timing and context

This makes the Gallery a powerful **debugging and validation tool**.

---

## Face Management from the Gallery

The Gallery is not only a viewer, but also a **management interface**.

From the Gallery you can:

- âž• Upload new training images
- ðŸ‘¤ Assign images to a person
- ðŸ—‘ Delete a person and all related images
- ðŸ§¹ Clear the entire face collection (with confirmation)
- ðŸ”„ Refresh the face index manually

All actions are executed in a safe and controlled way:
- AWS is updated
- Local cache is updated
- UI is refreshed instantly

---

## Recognized vs Unrecognized Faces

The Gallery clearly distinguishes between:

- **Recognized faces**
  - Shown with the personâ€™s name
  - Linked to the AWS face collection
- **Unrecognized faces**
  - Shown as unknown
  - Can be used to train new identities

This workflow allows you to:
- start with unknown faces
- progressively build your face collection
- improve recognition accuracy over time

---

## Gallery and ROI

When ROI is enabled:

- Only detections inside ROIs appear in the Gallery
- Snapshots still show the full image
- Bounding boxes are drawn only for ROI-based detections

This ensures consistency between:
- what is analyzed
- what is stored
- what is displayed

---

## Gallery and Storage Management

The Gallery respects all snapshot options:

- `max_saved_files`
- `save_timestamped_file`
- `always_save_latest_file`

When old files are deleted:
- the Gallery updates automatically
- no stale entries remain visible

---

## Gallery and Automations

The Gallery reflects the same data used by:
- sensors
- events
- automations

This means:
- what you see in the Gallery is exactly what Home Assistant reacts to
- no hidden detections or mismatches

---

## Typical Use Cases

- Validate face recognition accuracy
- Inspect false positives
- Review vehicle and plate detections
- Debug ROI configuration
- Train new faces from real events
- Monitor entrances, driveways and parking areas

---

## Summary

The Gallery is the **central visual interface** of the integration.

It allows you to:
- understand what the AI detects
- manage faces safely
- validate configuration choices
- keep AWS and Home Assistant perfectly aligned

For daily usage, debugging and long-term reliability, the Gallery is an essential part of the ecosystem.


## ROI - Region of Intesrest

![Amazon Face Recognition](images/roi.png)


ROI (Region of Interest) allows you to define **specific areas of the camera image** that should be analyzed by AWS Rekognition.

Only the defined regions are processed, while everything outside the ROI is ignored.

This is one of the most important features of the integration, as it improves **accuracy**, **performance**, and **cost efficiency**.

---

## Why use ROI

Using ROI provides several advantages:

- ðŸŽ¯ Focus detection only on relevant areas
- âŒ Ignore background or irrelevant zones
- ðŸ“‰ Reduce false positives
- ðŸ’° Lower AWS Rekognition costs
- âš¡ Improve overall performance

Typical examples:
- Analyze only the entrance door
- Ignore sidewalks or public roads
- Focus on a driveway instead of the whole street
- Exclude trees, sky, or neighboring areas

---

## How ROI works

- ROIs are defined **per camera**
- Each camera can have **multiple ROIs**
- ROIs are rectangular areas expressed as **normalized coordinates**
- During processing:
  - the image is cropped to each ROI
  - AWS Rekognition is executed only on those regions
  - results are mapped back to the original image
- Bounding boxes are drawn in the correct global position

Everything is handled transparently by the integration.

---

## Configuring ROI (GUI)

ROI configuration is performed **exclusively via the Custom Control Panel**.

### Steps:
1. Open the **Amazon Face Recognition Control Panel**
2. Select the **ROI** tab
3. Choose the camera you want to configure
4. Click **Add ROI**
5. Draw the ROI directly on the camera image
6. (Optional) Assign a name to the ROI
7. Save the configuration

Changes are applied immediately.

No YAML configuration is required.

---

## Multiple ROIs per camera

You can define more than one ROI for the same camera.

This is useful when:
- multiple entrances are visible
- you want to separate driveway and pedestrian areas
- different zones require different attention

Each ROI is processed independently.

---

## ROI and Detection Types

ROI affects **all detection types**, including:

- Face recognition
- Person detection
- Vehicle detection
- License plate recognition

If an object appears **outside** all defined ROIs, it will **not be detected**.

---

## ROI and Snapshots

- Only detections inside ROIs are included in snapshots
- Bounding boxes are drawn only for ROI-based detections
- The original image size is preserved
- Non-ROI areas remain visible but ignored

---

## ROI and Cost Optimization

ROI is the most effective way to reduce AWS costs.

Best practices:
- Keep ROIs as small as possible
- Avoid scanning large background areas
- Combine ROI with:
  - higher confidence thresholds
  - minimum area filters
  - vehicle limits

This drastically reduces the number of analyzed pixels and OCR calls.

---

## ROI Best Practices

### Entrance Door
- Small ROI around the door
- High confidence thresholds
- Ideal for face recognition

### Driveway
- Medium ROI covering vehicle path
- Combine with vehicle detection
- Limit max vehicles to scan

### Parking Area
- Larger ROI
- Lower vehicle area threshold
- Higher max vehicles (if needed)

---

## ROI and System Behavior

- If **no ROI is defined**, the **entire image is analyzed**
- ROI configuration is stored locally
- ROI settings persist across restarts
- ROI changes do not require a Home Assistant restart

---

## Summary

ROI allows you to transform generic image analysis into **precise, targeted detection**.

It is the recommended approach for:
- reliable face recognition
- vehicle and plate detection
- cost-efficient AWS usage

For best results, always combine ROI with appropriate confidence and area thresholds.


## Custom Card

![Amazon Face Recognition](images/custom_card2.png)

## Custom Lovelace Card

The **Amazon Face Recognition Custom Card** represents the visualization layer of the ecosystem.  
It is automatically available after installing the integration and provides an **interactive, read-only view** of analysis results directly inside Lovelace dashboards.

The card is designed to **display data generated by the backend**, without modifying it, ensuring full consistency with the Control Panel, Gallery, sensors and automations.

---

## Purpose of the Custom Card

The Custom Card allows you to:

- ðŸ–¼ Visualize **annotated snapshots**
- ðŸ” Interact with images (zoom, pan, reset)
- ðŸ’¾ Download snapshots to the local device
- ðŸŽ¥ Switch to **live camera view** of the camera that generated the snapshot
- ðŸ‘¤ View recognized and unrecognized faces
- ðŸ“‹ Display detected objects and vehicles (optional)
- ðŸš— Display recognized and unrecognized license plates
- ðŸ•’ Understand context with timestamps and camera information

All configuration and management actions are handled by the **Custom Control Panel**, not by the card.

---

## Automatic Availability

No separate installation is required.

- The card is automatically registered with Home Assistant
- No JavaScript resources need to be added
- No additional HACS steps are required

The card can be used immediately after installing the integration.

---

## Adding the Card to Lovelace

### UI Editor
1. Open a Lovelace dashboard
2. Click **Edit Dashboard**
3. Add a new card
4. Select **Amazon Face Recognition Card**
5. Choose the camera entity

### YAML Mode
```yaml
type: custom:aws-face-recognition-card
camera_entity: camera.front_door
```


##


---

## Internationalization

- Default language: **English**
- Automatically adapts to Home Assistant system language
- Supported languages:
  - English, Italian, French, Spanish, Portuguese, German, Polish

---

## Configuration philosophy (IMPORTANT)

âš ï¸ **Legacy YAML configuration is NOT supported.**

This integration is **100% GUI-based**:
- Config Flow
- Options Flow
- Custom Control Panel

All face-related operations are intentionally handled **only via the panel** to guarantee consistency between AWS, backend and UI.

---

## Installation (HACS)

1. Open **HACS**
2. Go to **Integrations**
3. Add this repository as a **Custom Repository**
4. Search for **Amazon Face Recognition**
5. Install and restart Home Assistant

---

## Getting started with AWS

Before using this integration, you need to configure AWS.

### 1. Sign up for an AWS account

To use Amazon Face Recognition, you first need an AWS account.  
AWS provides **12 months of Free Tier access**, which is enough for testing and light usage.

1. Open:  
   https://portal.aws.amazon.com

2. Fill in:
   - Email address
   - Password
   - AWS account name

3. Enter your address and phone number.

4. Add a **credit or debit card**  
   - A temporary charge of **1 USD / EUR** may be applied for verification.
   - The amount is refunded after a few days.
   - No extra charges apply if you stay within the Free Tier limits.

5. Verify your phone number with the code sent by AWS.

6. Select the **Basic Free Plan**.

> âš ï¸ A paid plan is **not required** for this integration.

---

## Create an Amazon Face Recognition IAM User

For security reasons, Home Assistant should **not** use the root AWS account.

We will create a dedicated user using **AWS Identity and Access Management (IAM)**.

### Step 1 â€“ Open IAM

1. Log in to the AWS Console.
2. Search for **IAM (Identity and Access Management)** and open it.

> ðŸ” Strongly recommended: enable **MFA (Multi-Factor Authentication)** on your AWS account.

---

### Step 2 â€“ Create a new user

1. Go to **Users** â†’ **Add users**
2. Choose a username (example: `homeassistant-face-recognition`)
3. Select:
   - âœ… **Programmatic access**
4. Click **Next**

---

### Step 3 â€“ Assign permissions

1. Select **Attach existing policies directly**
2. Search for **Rekognition**
3. Select:
   - âœ… `AmazonRekognitionFullAccess`
4. Click **Next**

---

### Step 4 â€“ Save credentials (IMPORTANT)

After creating the user, AWS will show:

- **Access Key ID**
- **Secret Access Key**

âš ï¸ Save them now.  
You will need them in Home Assistant and **AWS will not show the secret key again**.

---

## Create a Face Collection and get the Collection ID

A **face collection** is where Amazon Face Recognition stores the faces you want to recognize.

You only need **one collection**.

### Step 1 â€“ Open Amazon Rekognition

1. In the AWS Console, search for **Rekognition**
2. Make sure the selected **region** matches the one you will use in Home Assistant

> âš ï¸ In AWS, the service is still called **Amazon Rekognition**.

---

### Step 2 â€“ Create the collection

1. Open **Face collections**
2. Click **Create collection**
3. Enter a Collection ID  
   Example:
4. Click **Create**

---

### Step 3 â€“ Copy the Collection ID

ðŸ“Œ The **Collection ID** is the name you chose (e.g. `homeassistant_faces`).

âš ï¸ Do **not** use the Collection ARN.  
Home Assistant only needs the **Collection ID**.

---
---

## Home Assistant Setup

Add the integration from **Settings â†’ Devices & Services** and complete the configuration wizard.

---

## Automations

Use sensors and events to trigger actions based on recognized faces or vehicles.

---


# Options Flow â€“ Detailed Explanation

The following options are available in the **Options Flow (GUI)** and control **snapshot storage**, **overlay rendering (boxes & labels)** and **detection filtering**.

---

### `max_saved_files`
**What it does:**  
Limits how many historical snapshot files are kept in the snapshot directory.  
When the limit is exceeded, the oldest files are automatically deleted.

**How to configure:**
- Integer value (e.g. `10`, `50`, `200`)
- Lower values save disk space
- Higher values keep more history for debugging or auditing

**Recommended values:**
- `10â€“30` for testing
- `100+` if you want long-term history

---

### `save_file_format` (jpg / png)
**What it does:**  
Defines the image format used for saved snapshots.

- **jpg** â†’ smaller files, ideal for storage and notifications  
- **png** â†’ higher quality, but larger files

**How to configure:**  
Select the desired option in the UI.

**Recommendation:**  
Use `jpg` in most scenarios.

---

### `save_timestamped_file`
**What it does:**  
When enabled, the integration saves timestamped snapshot files such as:

recognition_20260115_173234.jpg

These files create the historical archive and populate the local gallery.

**How to configure:**
- âœ… Enabled: keep a snapshot history
- â›” Disabled: no historical files

**Recommendation:**  
Enable this option if you use the gallery or want event history.

---

### `always_save_latest_file`
**What it does:**  
Always saves (and overwrites) a fixed file representing the latest scan result  
(e.g. `recognition_latest.jpg`).

**Key difference:**
- `save_timestamped_file` â†’ multiple historical files
- `always_save_latest_file` â†’ one constantly updated file

**Typical use cases:**
- Dashboards showing the latest snapshot
- Notifications referencing a fixed image path
- Continuous monitoring / debugging

**Recommendation:**  
Enable this option in most setups.

---

### `show_boxes`
**What it does:**  
Enables or disables drawing bounding boxes and labels on saved images.

- âœ… Enabled: annotated snapshots
- â›” Disabled: clean images without overlays

**Recommendation:**  
Enable for visibility and debugging, disable if you prefer clean images.

---

### `s3_bucket`
**What it does:**  
If set, snapshots are also uploaded to the specified **AWS S3 bucket**.

**How to configure:**
- Enter the bucket name (e.g. `my-homeassistant-bucket`)
- Leave empty to disable S3 upload

**Important notes:**
- The IAM user must have S3 permissions
- Useful for external access, backups or integrations

---

### `label_font_level`
**What it does:**  
Controls the size of the text labels drawn on bounding boxes.

- Higher value â†’ larger text
- Lower value â†’ smaller text

**How to configure:**  
Slider with numeric value (e.g. `6`).

**Recommendations:**
- `4â€“6` works well for most cameras
- Increase for mobile viewing
- Decrease if labels cover too much of the image

---

### `max_red_boxes`
**What it does:**  
Limits the maximum number of red bounding boxes drawn on a snapshot  
(typically used for unrecognized persons or people detections).

This prevents images from becoming cluttered when many detections occur.

**How to configure:**
- Slider with numeric value
- Common values: `3â€“10`

**Examples:**
- `3` â†’ only the most relevant detections
- `10` â†’ more complete but noisier view

---

### `min_red_box_area_pct`
**What it does:**  
Filters out very small bounding boxes based on image area percentage.

- Higher value â†’ more aggressive filtering
- Lower value â†’ more sensitive detection

**How to configure:**
- Percentage slider (typically `0â€“5%`)

**Practical advice:**
- Increase if you see distant false positives
- Decrease if you miss valid distant detections

---

### `default_min_confidence`
**What it does:**  
Defines the global minimum confidence threshold for detections.

- Higher value â†’ fewer false positives
- Lower value â†’ more detections, more noise

**How to configure:**  
Numeric value (typically `10â€“100`).

**Recommendations:**
- Faces / persons: `70â€“90`
- Generic objects: `50â€“80`

> This value is used as a fallback if no per-target confidence is defined.

---

### `targets_confidence`
**What it does:**  
Allows defining **specific confidence thresholds per target**.

This field accepts a key-value mapping where:
- key = target label
- value = minimum confidence

**Example:**
```yaml
car: 50
person: 80

```



---

### `excluded_object_labels`
**What it does:**  
Defines a list of object labels that should be **completely excluded** from processing and summaries.

Unlike `exclude_targets`, this option is specifically intended to:
- remove unwanted object labels from the **final result set**
- avoid clutter in summaries and UI
- reduce noise caused by generic detections

**Typical use cases:**
- Ignore objects such as `tree`, `plant`, `road`, `building`
- Remove labels that are not relevant for automations

**How to configure:**  
Enter one label per line.

**Example:**
```yaml
tree
plant
road
```


**Effect:**  
Excluded object labels will not:
- appear in detection summaries
- trigger events
- be considered for automations

---

### `aws_api_cost`
**What it does:**  
Defines the **estimated cost per AWS Rekognition API call**, used for internal usage and cost statistics.

This value **does not affect AWS billing**.  
It is used only to:
- estimate monthly costs
- populate usage sensors
- provide transparency in Home Assistant

**Default value:**

```yaml
0.0001$
```

**Meaning:**  
Approximately **$0.001 per image scan** (1,000 scans â‰ˆ $1), which matches AWS Rekognition pricing for image analysis.

**When to change it:**
- If AWS pricing changes
- If you want to adapt estimates to your region or usage model

---

### `scan_cars`
**What it does:**  
Enables or disables **vehicle detection and license plate recognition**.

When enabled, the integration will:
- detect vehicles (car, truck, motorcycle, bus)
- perform license plate OCR
- populate the Plates panel
- generate vehicle-related events

**How to configure:**
- âœ… Enabled: vehicle and plate detection active
- â›” Disabled: only face/object detection

**Recommendation:**  
Enable only if you need vehicle or plate recognition, to reduce AWS usage.

---

### `vehicle_area_abs_min`
**What it does:**  
Defines the **minimum vehicle bounding box size**, expressed as a percentage of the image area.

This filters out:
- very small vehicles
- distant detections
- common false positives

**How to configure:**
- Percentage slider (e.g. `1%`)

**Examples:**
- `1%`: balanced default
- `2â€“3%`: aggressive filtering (near vehicles only)
- `<1%`: very sensitive (detect distant vehicles)

**Recommendation:**  
Increase this value if you see many false vehicle detections.

---

### `max_vehicles_to_scan`
**What it does:**  
Limits the **maximum number of vehicles analyzed per image**.

This helps to:
- control AWS usage
- avoid unnecessary OCR scans
- improve performance in crowded scenes

**How to configure:**
- Slider with numeric value

**Examples:**
- `1â€“2`: ideal for driveways or private entrances
- `3â€“5`: suitable for small parking areas
- Higher values: useful for large scenes but increase cost

**Recommendation:**  
Keep this value as low as possible for your scenario.

---

## Vehicle Detection Configuration Examples

### Driveway / Private Entrance
- `scan_cars`: enabled
- `vehicle_area_abs_min`: `1â€“2%`
- `max_vehicles_to_scan`: `1`

### Parking Area
- `scan_cars`: enabled
- `vehicle_area_abs_min`: `0.5â€“1%`
- `max_vehicles_to_scan`: `3â€“5`

### No Vehicle Detection
- `scan_cars`: disabled

---

## Cost Optimization Tips

- Use **ROI** to limit scanned areas
- Disable `scan_cars` if not required
- Increase `vehicle_area_abs_min` to reduce OCR calls
- Limit `max_vehicles_to_scan`
- Monitor usage sensors in Home Assistant

These options allow you to precisely balance **accuracy**, **performance**, and **AWS costs**.



## Performance & Costs

ROI reduces AWS calls and costs.
AWS Free Tier is sufficient for testing.

https://aws.amazon.com/rekognition/pricing/

---

## Disclaimer

This project is not affiliated with Amazon or AWS.
Amazon Rekognition is a trademark of Amazon Web Services.
